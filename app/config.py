"""ì„¤ì • ê´€ë¦¬ ëª¨ë“ˆ"""
import os
from pathlib import Path
from typing import List, Dict, Any
import yaml
from pydantic import BaseModel
from pydantic_settings import BaseSettings


class ModelConfig(BaseModel):
    """ëª¨ë¸ ì„¤ì •"""
    name: str
    display_name: str
    context_length: int


class ServerConfig(BaseModel):
    """ì„œë²„ ì„¤ì •"""
    host: str = "0.0.0.0"
    port: int = 8000
    workers: int = 4
    log_level: str = "info"


class CloudflareConfig(BaseModel):
    """Cloudflare Tunnel ì„¤ì •"""
    enabled: bool = False
    tunnel_name: str = "llm-api"


class OpenAIConfig(BaseModel):
    """OpenAI ì„¤ì •"""
    api_key: str = ""
    enabled: bool = True
    timeout: int = 120


class AuthConfig(BaseModel):
    """ì¸ì¦ ì„¤ì •"""
    enabled: bool = False  # ê¸°ë³¸ê°’: ì¸ì¦ ë¹„í™œì„±í™” (ì™¸ë¶€ì—ì„œë„ í‚¤ ì—†ì´ ì ‘ê·¼ ê°€ëŠ¥)


class RateLimitConfig(BaseModel):
    """Rate Limiting ì„¤ì •"""
    enabled: bool = True
    requests_per_minute: int = 60
    tokens_per_minute: int = 100000


class CORSConfig(BaseModel):
    """CORS ì„¤ì •"""
    allowed_origins: List[str] = ["*"]


class LoadBalancingConfig(BaseModel):
    """ë¡œë“œë°¸ëŸ°ì‹± ì„¤ì •"""
    enabled: bool = True
    auto_fallback: bool = True
    prefer_local: bool = True
    local_model: str = "vllm-qwen3-30b-a3b"
    cloud_model: str = "gpt-5-mini"
    max_queue_size: int = 4
    max_wait_time: float = 3.0


class AppConfig(BaseModel):
    """ì „ì²´ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •"""
    server: ServerConfig
    cloudflare: CloudflareConfig
    openai: OpenAIConfig
    default_model: str
    available_models: List[ModelConfig]
    auth: AuthConfig
    rate_limit: RateLimitConfig
    cors: CORSConfig
    load_balancing: LoadBalancingConfig = LoadBalancingConfig()


class Settings(BaseSettings):
    """í™˜ê²½ë³€ìˆ˜ ì„¤ì •"""
    ADMIN_API_KEY: str = "sk-admin-change-me"
    OPENAI_API_KEY: str = ""
    SERVER_HOST: str = "0.0.0.0"
    SERVER_PORT: int = 8000
    DATABASE_PATH: str = "./data/llm_server.db"

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"


def is_railway_environment() -> bool:
    """Railway í™˜ê²½ì¸ì§€ í™•ì¸"""
    return os.environ.get("DEPLOY_ENV") == "railway" or os.environ.get("RAILWAY_ENVIRONMENT") is not None


def load_config(config_path: str = None) -> AppConfig:
    """YAML ì„¤ì • íŒŒì¼ ë¡œë“œ (í™˜ê²½ì— ë”°ë¼ ìžë™ ì„ íƒ)"""
    # ì„¤ì • íŒŒì¼ ê²½ë¡œ ìžë™ ì„ íƒ
    if config_path is None:
        if is_railway_environment():
            config_path = "config.railway.yaml"
            print("ðŸš‚ Railway í™˜ê²½ ê°ì§€ - config.railway.yaml ì‚¬ìš©")
        else:
            config_path = "config.yaml"
            print("ðŸ–¥ï¸  ë¡œì»¬ í™˜ê²½ - config.yaml ì‚¬ìš©")

    config_file = Path(config_path)

    if not config_file.exists():
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")

    with open(config_file, "r", encoding="utf-8") as f:
        config_data = yaml.safe_load(f)

    return AppConfig(**config_data)


# ì „ì—­ ì„¤ì • ê°ì²´
settings = Settings()
app_config: AppConfig = None


def get_config() -> AppConfig:
    """ì•± ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
    global app_config
    if app_config is None:
        app_config = load_config()
    return app_config


def get_settings() -> Settings:
    """í™˜ê²½ë³€ìˆ˜ ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
    return settings
